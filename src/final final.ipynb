{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gxgp\n",
    "from gxgp import DagGP, Node\n",
    "import operator\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Define custom mathematical functions\n",
    "# -------------------------------\n",
    "def custom_sin(x):\n",
    "    \"\"\"Sine function that handles numpy arrays.\"\"\"\n",
    "    return np.sin(x)\n",
    "\n",
    "def custom_cos(x):\n",
    "    \"\"\"Cosine function that handles numpy arrays.\"\"\"\n",
    "    return np.cos(x)\n",
    "\n",
    "def custom_exp(x):\n",
    "    \"\"\"Exponential function that handles numpy arrays safely.\"\"\"\n",
    "    # Clip x to prevent overflow\n",
    "    clipped_x = np.clip(x, -100, 100)\n",
    "    return np.exp(clipped_x)\n",
    "\n",
    "def safe_div(x, y):\n",
    "    \"\"\"Division function that prevents division by zero.\"\"\"\n",
    "    return x / (y + 1e-6)  # Add small epsilon to avoid division by zero\n",
    "\n",
    "def square(x):\n",
    "    \"\"\"Square function.\"\"\"\n",
    "    return x ** 2\n",
    "\n",
    "def safe_exp(x):\n",
    "    \"\"\"Exponential function that prevents overflow.\"\"\"\n",
    "    # Clip x to a reasonable maximum value\n",
    "    clipped_x = np.clip(x, -100, 100)  # Adjust these bounds as needed\n",
    "    return np.exp(clipped_x)\n",
    "\n",
    "def safe_log(x):\n",
    "    \"\"\"Protected logarithm: returns log(abs(x)+epsilon) to avoid log(0).\"\"\"\n",
    "    return np.log(np.abs(x) + 1e-6)\n",
    "\n",
    "def safe_sqrt(x):\n",
    "    \"\"\"Protected square root: returns sqrt(abs(x)) so the argument is non-negative.\"\"\"\n",
    "    return np.sqrt(np.abs(x))\n",
    "\n",
    "def custom_tanh(x):\n",
    "    \"\"\"Hyperbolic tangent function that handles numpy arrays.\"\"\"\n",
    "    return np.tanh(x)\n",
    "\n",
    "def safe_pow(x, y):\n",
    "    \"\"\"Protected power function: returns abs(x) raised to the power y safely.\n",
    "       This version clips the base and avoids division by zero issues.\"\"\"\n",
    "    epsilon = 1e-6\n",
    "    # Take the absolute value and replace near-zero values with epsilon\n",
    "    base = np.abs(x)\n",
    "    base = np.where(base < epsilon, epsilon, base)\n",
    "    # Clip the base to avoid extremely large numbers that cause overflow.\n",
    "    base = np.clip(base, 0, 100)\n",
    "    return np.power(base, y)\n",
    "\n",
    "def cube(x):\n",
    "    \"\"\"Cube function.\"\"\"\n",
    "    return x ** 3\n",
    "\n",
    "def reciprocal(x):\n",
    "    \"\"\"Reciprocal function with protection against division by zero.\"\"\"\n",
    "    return 1.0 / (x + 1e-6)\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"Sigmoid activation function.\"\"\"\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def gaussian(x):\n",
    "    \"\"\"Gaussian function.\"\"\"\n",
    "    return np.exp(-x ** 2)\n",
    "\n",
    "def relu(x):\n",
    "    \"\"\"Rectified Linear Unit function.\"\"\"\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def leaky_relu(x, alpha=0.01):\n",
    "    \"\"\"Leaky ReLU function.\"\"\"\n",
    "    return np.where(x > 0, x, alpha * x)\n",
    "\n",
    "def elu(x, alpha=1.0):\n",
    "    \"\"\"Exponential Linear Unit function.\"\"\"\n",
    "    return np.where(x > 0, x, alpha * (np.exp(x) - 1))\n",
    "\n",
    "def swish(x):\n",
    "    \"\"\"Swish activation function.\"\"\"\n",
    "    return x * sigmoid(x)\n",
    "\n",
    "def mish(x):\n",
    "    \"\"\"Mish activation function.\"\"\"\n",
    "    return x * np.tanh(np.log1p(np.exp(x)))\n",
    "\n",
    "\n",
    "def sin1_over_x(x):\n",
    "    \"\"\"Sine of 1/x function with protection against division by zero.\"\"\"\n",
    "    return np.sin(1.0 / (x + 1e-6))\n",
    "\n",
    "def sinc(x):\n",
    "    \"\"\"Sinc function.\"\"\"\n",
    "    return np.sinc(x / np.pi)\n",
    "\n",
    "def sawtooth(x):\n",
    "    \"\"\"Sawtooth wave function.\"\"\"\n",
    "    return 2 * (x / (2 * np.pi) - np.floor(0.5 + x / (2 * np.pi)))\n",
    "\n",
    "def triangle_wave(x):\n",
    "    \"\"\"Triangle wave function.\"\"\"\n",
    "    return 2 * np.abs(2 * (x / (2 * np.pi) - np.floor(x / (2 * np.pi) + 0.5))) - 1\n",
    "\n",
    "def square_wave(x):\n",
    "    \"\"\"Square wave function.\"\"\"\n",
    "    return np.sign(np.sin(x))\n",
    "\n",
    "\n",
    "def bent_identity(x):\n",
    "    \"\"\"Bent identity function.\"\"\"\n",
    "    return (np.sqrt(x ** 2 + 1) - 1) / 2 + x\n",
    "\n",
    "def softsign(x):\n",
    "    \"\"\"Softsign function.\"\"\"\n",
    "    return x / (1 + np.abs(x))\n",
    "\n",
    "def hard_sigmoid(x):\n",
    "    \"\"\"Hard sigmoid function.\"\"\"\n",
    "    return np.clip((x + 1) / 2, 0, 1)\n",
    "\n",
    "def logit(x):\n",
    "    \"\"\"Logit function with protection against division by zero.\"\"\"\n",
    "    x = np.clip(x, 1e-6, 1 - 1e-6)\n",
    "    return np.log(x / (1 - x))\n",
    "\n",
    "\n",
    "def mod(x, y):\n",
    "    \"\"\"Modulo operation with protection against division by zero.\"\"\"\n",
    "    return np.mod(x, y + 1e-6)\n",
    "\n",
    "def max_op(x, y):\n",
    "    \"\"\"Maximum of two values.\"\"\"\n",
    "    return np.maximum(x, y)\n",
    "\n",
    "def min_op(x, y):\n",
    "    \"\"\"Minimum of two values.\"\"\"\n",
    "    return np.minimum(x, y)\n",
    "\n",
    "def average(x, y):\n",
    "    \"\"\"Average of two values.\"\"\"\n",
    "    return (x + y) / 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# -------------------------------\n",
    "# Load problem data\n",
    "# -------------------------------\n",
    "selected_problem = 8\n",
    "data = np.load(f'../data/problem_{selected_problem}.npz')\n",
    "x_data = data['x']\n",
    "y_data = data['y']\n",
    "\n",
    "MAX_SAMPLES = 2000\n",
    "if y_data.shape[0] > MAX_SAMPLES:\n",
    "    step = y_data.shape[0] // MAX_SAMPLES\n",
    "    y_true = y_data[::step][:MAX_SAMPLES]\n",
    "    x_data = x_data[:, ::step][:, :MAX_SAMPLES]\n",
    "else:\n",
    "    y_true = y_data\n",
    "\n",
    "# Transpose x_data so that each row is one sample and each column is one variable.\n",
    "x_data = x_data.T  \"\"\"\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Load problem data\n",
    "# -------------------------------\n",
    "selected_problem = 8\n",
    "data = np.load(f'../data/problem_{selected_problem}.npz')\n",
    "x_data = data['x']\n",
    "y_data = data['y']\n",
    "\n",
    "MAX_SAMPLES = 2000\n",
    "num_samples = y_data.shape[0]\n",
    "\n",
    "if num_samples > MAX_SAMPLES:\n",
    "    # Randomly choose MAX_SAMPLES indices without replacement\n",
    "    indices = np.random.choice(num_samples, size=MAX_SAMPLES, replace=False)\n",
    "else:\n",
    "    indices = np.arange(num_samples)\n",
    "\n",
    "# Sort indices for consistent plotting (optional)\n",
    "indices = np.sort(indices)\n",
    "\n",
    "# Select the same indices from both x and y\n",
    "y_true = y_data[indices]\n",
    "x_data = x_data[:, indices]\n",
    "\n",
    "# Transpose x_data so that each row is one sample and each column is one variable.\n",
    "x_data = x_data.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Set up operators and GP parameters\n",
    "# -------------------------------\n",
    "# Use one consistent set of operators\n",
    "operators = [\n",
    "    operator.add,       # binary: +\n",
    "    operator.sub,       # binary: -\n",
    "    operator.mul,       # binary: *\n",
    "    safe_div,           # binary: protected division\n",
    "    square,             # unary: square\n",
    "    cube,               # unary: cube\n",
    "    custom_sin,         # unary: sine\n",
    "    custom_cos,         # unary: cosine\n",
    "    custom_exp,         # unary: exponential (with clipping)\n",
    "    safe_log,           # unary: protected logarithm\n",
    "    safe_sqrt,          # unary: protected square root\n",
    "    custom_tanh,        # unary: tanh\n",
    "    safe_pow,           # binary: protected power\n",
    "    reciprocal,         # unary: reciprocal\n",
    "    sigmoid,            # unary: sigmoid\n",
    "    gaussian,           # unary: gaussian\n",
    "    relu,               # unary: ReLU\n",
    "    leaky_relu,         # unary: leaky ReLU\n",
    "    elu,                # unary: ELU\n",
    "    swish,              # unary: swish\n",
    "    mish,               # unary: mish\n",
    "    sin1_over_x,        # unary: sin(1/x)\n",
    "    sinc,               # unary: sinc\n",
    "    sawtooth,           # unary: sawtooth wave\n",
    "    triangle_wave,      # unary: triangle wave\n",
    "    square_wave,        # unary: square wave\n",
    "    bent_identity,      # unary: bent identity\n",
    "    softsign,           # unary: softsign\n",
    "    hard_sigmoid,       # unary: hard sigmoid\n",
    "    logit,              # unary: logit\n",
    "    mod,                # binary: modulo\n",
    "    max_op,             # binary: max\n",
    "    min_op,             # binary: min\n",
    "    average             # binary: average\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Adjusted parameter settings to allow for more growth and complexity\n",
    "POP_SIZE = 2000          \n",
    "NUM_GENS = 100         \n",
    "OFFSPRING_NUM = 1500      \n",
    "INITIAL_SIZE_MIN = 1    # Minimum size for initial trees\n",
    "INITIAL_SIZE_MAX = 25   # Maximum size for initial trees \n",
    "TOURN_SIZE = 250        \n",
    "LENGTH_PENALTY = 0.00001 \n",
    "CROSSOVER_PROB = 0.7    \n",
    "MUTATION_PROB = 0.3     \n",
    "MAX_TREE_DEPTH = 10     # Maximum depth for any tree to prevent bloat\n",
    "ADAPTIVE_PENALTY = True # Enable adaptive complexity penalty\n",
    "MIN_SEMANTIC_THRESHOLD = 0.05 \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Initialize the GP system with consistent operators\n",
    "# -------------------------------\n",
    "# Note: Ensure that 'operators' is defined in your context.\n",
    "\n",
    "\n",
    "\n",
    "gp = DagGP(\n",
    "    operators=operators,\n",
    "    variables=x_data.shape[1],\n",
    "    constants=np.linspace(-5, 5, 2000)\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Tree Structure Functions\n",
    "# -------------------------------\n",
    "\n",
    "def has_cycle(node, visited=None):\n",
    "    \"\"\"Check if a tree has cycles, which should be avoided in GP.\"\"\"\n",
    "    if visited is None:\n",
    "        visited = set()\n",
    "    if id(node) in visited:\n",
    "        return True\n",
    "    visited.add(id(node))\n",
    "    for child in node.successors:\n",
    "        if has_cycle(child, visited.copy()):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def validate_and_fix_tree(root):\n",
    "    \"\"\"If a tree has cycles, replace it with a valid one.\"\"\"\n",
    "    if has_cycle(root):\n",
    "        new_size = np.random.randint(INITIAL_SIZE_MIN, INITIAL_SIZE_MAX + 1)\n",
    "        return gp.create_individual(new_size)\n",
    "    return root\n",
    "\n",
    "\n",
    "def collect_nodes(node, nodes_list=None):\n",
    "    \"\"\"Collect all nodes in a tree into a list.\"\"\"\n",
    "    if nodes_list is None:\n",
    "        nodes_list = []\n",
    "    nodes_list.append(node)\n",
    "    for child in node.successors:\n",
    "        collect_nodes(child, nodes_list)\n",
    "    return nodes_list\n",
    "\n",
    "def get_tree_depth(node, depth=0, max_depth=0):\n",
    "    \"\"\"Calculate the maximum depth of a tree.\"\"\"\n",
    "    current_depth = depth + 1\n",
    "    max_depth = max(max_depth, current_depth)\n",
    "    for child in node.successors:\n",
    "        max_depth = get_tree_depth(child, current_depth, max_depth)\n",
    "    return max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Define an improved fitness evaluation function with adaptive complexity penalty\n",
    "# -------------------------------\n",
    "def unified_compute_fitness(ind, generation=0, adaptive=True):\n",
    "    \n",
    "    ind = validate_and_fix_tree(ind)\n",
    "\n",
    "    try:\n",
    "        pred = gp.evaluate(ind, x_data, variable_names=[f'x{i}' for i in range(x_data.shape[1])])\n",
    "        pred = np.array(pred)\n",
    "\n",
    "        if np.any(np.isnan(pred)) or np.any(np.isinf(pred)):\n",
    "            return -1e30  # Extremely bad fitness\n",
    "\n",
    "        mse_val = np.mean((pred - y_true) ** 2)\n",
    "\n",
    "        complexity = len(collect_nodes(ind))\n",
    "\n",
    "        #base_penalty = 0.001\n",
    "        penalty_weight = LENGTH_PENALTY * max(0.1, 1.0 - generation / NUM_GENS)\n",
    "\n",
    "        total_penalty = penalty_weight * complexity\n",
    "\n",
    "        fitness = -(mse_val + total_penalty)\n",
    "        return fitness\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Fitness evaluation failed: {e}\")\n",
    "        return -1e30\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def semantic_distance(ind1, ind2, x_data):\n",
    "    y1 = np.array(gp.evaluate(ind1, x_data))\n",
    "    y2 = np.array(gp.evaluate(ind2, x_data))\n",
    "    return np.mean(np.abs(y1 - y2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Helper functions for mutation and crossover\n",
    "# -------------------------------\n",
    "def get_mutation_strategies(current_size, growth_factor):\n",
    "    \"\"\"Determine mutation strategies and their probabilities based on tree size.\"\"\"\n",
    "    if current_size < 15:  # For smaller trees, encourage growth more aggressively\n",
    "        strategies = [\n",
    "            (\"point_mutation\", max(0.1, 0.35 - growth_factor * 0.2)),\n",
    "            (\"subtree_replacement\", max(0.1, 0.35 - growth_factor * 0.2)),\n",
    "            (\"grow\", min(0.7, 0.2 + growth_factor * 0.4)),  # Increase growth probability\n",
    "            (\"shrink\", max(0.05, 0.1 - growth_factor * 0.05))\n",
    "        ]\n",
    "    else:  # For larger trees, balanced approach\n",
    "        strategies = [\n",
    "            (\"point_mutation\", 0.25),\n",
    "            (\"subtree_replacement\", 0.25),\n",
    "            (\"grow\", 0.4),  # Still significant growth probability\n",
    "            (\"shrink\", 0.1)\n",
    "        ]\n",
    "    \n",
    "    # Normalize probabilities to ensure they sum to 1.0\n",
    "    total_prob = sum(prob for _, prob in strategies)\n",
    "    return [(name, prob/total_prob) for name, prob in strategies]\n",
    "\n",
    "\n",
    "def select_mutation_strategy(strategies):\n",
    "    \"\"\"Select a mutation strategy based on probabilities.\"\"\"\n",
    "    strategy_names, probabilities = zip(*strategies)\n",
    "    return np.random.choice(strategy_names, p=probabilities)\n",
    "\n",
    "\n",
    "def select_node_for_mutation(all_nodes, mutation_type):\n",
    "    \"\"\"Select a node to mutate with bias toward leaf nodes for growth operations.\"\"\"\n",
    "    if mutation_type == \"grow\" and len(all_nodes) > 1:\n",
    "        # Separate nodes into internal and leaf nodes\n",
    "        leaf_nodes = [node for node in all_nodes if node.is_leaf]\n",
    "        if leaf_nodes and np.random.rand() < 0.7:  # 70% chance to select a leaf node for growth\n",
    "            return np.random.choice(leaf_nodes)\n",
    "    \n",
    "    return np.random.choice(all_nodes)\n",
    "\n",
    "def replace_subtree(node, new_subtree, parent=None, parent_idx=None):\n",
    "\n",
    "    # If we have direct parent access, we can replace the entire node\n",
    "    if parent is not None and parent_idx is not None:\n",
    "        parent_successors = list(parent.successors)\n",
    "        parent_successors[parent_idx] = new_subtree\n",
    "        try:\n",
    "            parent.successors = parent_successors\n",
    "            return True\n",
    "        except AssertionError:\n",
    "            return False\n",
    "    \n",
    "    # If node and new_subtree have the same number of successors, we can replace content\n",
    "    if len(node.successors) == len(new_subtree.successors):\n",
    "        if hasattr(node, '_op') and hasattr(new_subtree, '_op'):\n",
    "            node._op = new_subtree._op\n",
    "        \n",
    "        if hasattr(node, '_data') and hasattr(new_subtree, '_data'):\n",
    "            node._data = new_subtree._data\n",
    "            \n",
    "        if hasattr(node, 'name') and hasattr(new_subtree, 'name'):\n",
    "            node.name = new_subtree.name\n",
    "        \n",
    "        for i, successor in enumerate(new_subtree.successors):\n",
    "            node_successors = list(node.successors)\n",
    "            node_successors[i] = successor\n",
    "            node.successors = node_successors\n",
    "            \n",
    "        return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "def find_parent_and_index(root, node, path=None):\n",
    "    if path is None:\n",
    "        path = []\n",
    "    \n",
    "    # Check if any of root's successors is the target node\n",
    "    for i, child in enumerate(root.successors):\n",
    "        if child is node:\n",
    "            return root, i\n",
    "    \n",
    "    for i, child in enumerate(root.successors):\n",
    "        result = find_parent_and_index(child, node, path + [(root, i)])\n",
    "        if result is not None:\n",
    "            return result\n",
    "    \n",
    "    return None\n",
    "\n",
    "def apply_point_mutation(ind, node, gp_instance, current_depth, max_depth):\n",
    "    if not node.is_leaf:\n",
    "        new_op = np.random.choice(operators)\n",
    "        # Create a small new subtree if there is room\n",
    "        if current_depth < max_depth:\n",
    "            # Generate a subtree with potentially more complex structure\n",
    "            depth_allowance = max_depth - current_depth + 1\n",
    "            max_new_depth = min(3, depth_allowance)\n",
    "            new_subtree = gp_instance.create_individual(np.random.randint(2, max_new_depth + 1))\n",
    "            replace_subtree(node, new_subtree)\n",
    "    return ind\n",
    "\n",
    "\n",
    "def apply_subtree_replacement(ind, node, gp_instance, generation, current_depth, max_depth):\n",
    "    if current_depth >= max_depth:\n",
    "        return ind\n",
    "        \n",
    "    parent_info = find_parent_and_index(ind, node)\n",
    "    \n",
    "    # Create a new subtree\n",
    "    base_size = 3 + int((generation / NUM_GENS) * 5)\n",
    "    size_range = max(2, base_size + np.random.randint(0, 3))\n",
    "    new_size = np.random.randint(2, size_range + 1)\n",
    "    \n",
    "    # Try up to 5 times to create a compatible subtree\n",
    "    for _ in range(5):\n",
    "        new_subtree = gp_instance.create_individual(new_size)\n",
    "        \n",
    "        # If we have parent info, try direct replacement\n",
    "        if parent_info:\n",
    "            parent, idx = parent_info\n",
    "            parent_successors = list(parent.successors)\n",
    "            parent_successors[idx] = new_subtree\n",
    "            try:\n",
    "                parent.successors = parent_successors\n",
    "                return ind\n",
    "            except AssertionError:\n",
    "                continue  # Try again with a new subtree\n",
    "        \n",
    "        # If node and new_subtree have same arity, try content replacement\n",
    "        if len(node.successors) == len(new_subtree.successors):\n",
    "            success = replace_subtree(node, new_subtree)\n",
    "            if success:\n",
    "                return ind\n",
    "    \n",
    "    # If all attempts failed, return unchanged individual\n",
    "    return ind\n",
    "\n",
    "def apply_grow_mutation(ind, node, gp_instance, generation, current_depth, max_depth):\n",
    "    if current_depth >= max_depth:\n",
    "        return ind\n",
    "        \n",
    "    # If node is a leaf, find its parent to replace it\n",
    "    if node.is_leaf:\n",
    "        parent_info = find_parent_and_index(ind, node)\n",
    "        if parent_info:\n",
    "            parent, idx = parent_info\n",
    "            \n",
    "            # Create a new subtree\n",
    "            max_growth = max(3, int(2 + (generation / NUM_GENS) * 5))\n",
    "            new_size = np.random.randint(2, max_growth + 1)\n",
    "            \n",
    "            # Try up to 5 times to create a compatible replacement\n",
    "            for _ in range(5):\n",
    "                new_subtree = gp_instance.create_individual(new_size)\n",
    "                parent_successors = list(parent.successors)\n",
    "                parent_successors[idx] = new_subtree\n",
    "                try:\n",
    "                    parent.successors = parent_successors\n",
    "                    return ind\n",
    "                except AssertionError:\n",
    "                    continue  # Try again\n",
    "    else:\n",
    "        # For non-leaf nodes, try to replace one of its children with a larger subtree\n",
    "        if node.successors:\n",
    "            child_idx = np.random.randint(0, len(node.successors))\n",
    "            child = node.successors[child_idx]\n",
    "            \n",
    "            # Create a new subtree\n",
    "            max_growth = max(3, int(2 + (generation / NUM_GENS) * 5))\n",
    "            new_size = np.random.randint(2, max_growth + 1)\n",
    "            \n",
    "            # Try up to 5 times to create a compatible replacement\n",
    "            for _ in range(5):\n",
    "                new_subtree = gp_instance.create_individual(new_size)\n",
    "                node_successors = list(node.successors)\n",
    "                node_successors[child_idx] = new_subtree\n",
    "                try:\n",
    "                    node.successors = node_successors\n",
    "                    return ind\n",
    "                except AssertionError:\n",
    "                    continue  # Try again\n",
    "    \n",
    "    return ind\n",
    "\n",
    "\n",
    "def apply_shrink_mutation(ind, node):\n",
    "    if not node.is_leaf and node.successors:\n",
    "        # Find parent for the node to mutate\n",
    "        parent_nodes = [node for node in collect_nodes(ind) if node in node.successors]\n",
    "        if parent_nodes:\n",
    "            parent = parent_nodes[0]\n",
    "            parent_successors = parent.successors[:]\n",
    "            child_idx = parent_successors.index(node)\n",
    "            \n",
    "            # Replace with one of node's children\n",
    "            if node.successors:\n",
    "                replacement = np.random.choice(node.successors)\n",
    "                parent_successors[child_idx] = replacement\n",
    "                parent.successors = parent_successors\n",
    "    return ind\n",
    "\n",
    "def select_crossover_point(nodes, growth_bias):\n",
    "    # Skip root node\n",
    "    if len(nodes) <= 1:\n",
    "        return None\n",
    "    \n",
    "    # Separate internal nodes (with children) from leaf nodes\n",
    "    internal_nodes = [n for n in nodes[1:] if not n.is_leaf]\n",
    "    \n",
    "    # If we have internal nodes, use them with higher probability based on growth bias\n",
    "    if internal_nodes and np.random.rand() < growth_bias:\n",
    "        return np.random.choice(internal_nodes)\n",
    "    else:\n",
    "        return np.random.choice(nodes[1:])  # Skip root\n",
    "\n",
    "def swap_subtrees(parent1, parent2, point1, point2):\n",
    "    # Get index of crossover points\n",
    "    idx1 = parent1.successors.index(point1)\n",
    "    idx2 = parent2.successors.index(point2)\n",
    "    \n",
    "    # Swap subtrees\n",
    "    successors1 = parent1.successors[:]\n",
    "    successors2 = parent2.successors[:]\n",
    "    successors1[idx1], successors2[idx2] = point2, point1\n",
    "    parent1.successors = successors1\n",
    "    parent2.successors = successors2\n",
    "\n",
    "def is_valid_depth(child1, child2, generation):\n",
    "    depth1 = get_tree_depth(child1)\n",
    "    depth2 = get_tree_depth(child2)\n",
    "    \n",
    "    # More permissive depth check that relaxes as generations progress\n",
    "    max_allowed_depth = MAX_TREE_DEPTH\n",
    "    if np.random.rand() < (generation / NUM_GENS) * 0.3:\n",
    "        # Occasionally allow slightly deeper trees in later generations\n",
    "        max_allowed_depth += 2\n",
    "        \n",
    "    return depth1 <= max_allowed_depth and depth2 <= max_allowed_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Streamlined Selection, Mutation, and Crossover Operations\n",
    "# -------------------------------\n",
    "def tournament_select(pop, generation=0, size_aware=False):\n",
    "    \n",
    "    participants = np.random.choice(pop, size=min(TOURN_SIZE, len(pop)), replace=False)\n",
    "    \n",
    "    if size_aware and np.random.rand() < min(0.3, (generation / NUM_GENS) * 0.4):\n",
    "        avg_size = np.mean([len(collect_nodes(ind)) for ind in pop])\n",
    "        \n",
    "        # Occasionally favor larger trees if they're above average size\n",
    "        # but not too far below average fitness\n",
    "        sorted_participants = sorted(participants, key=lambda ind: ind.fitness, reverse=True)\n",
    "        \n",
    "        for ind in sorted_participants:\n",
    "            ind_size = len(collect_nodes(ind))\n",
    "            if ind_size > avg_size * 1.2:  # Tree is 20% larger than average\n",
    "                # If fitness is at least 80% of the best participant, select it\n",
    "                best_fitness = sorted_participants[0].fitness\n",
    "                if ind.fitness >= best_fitness * 0.8:\n",
    "                    return ind\n",
    "    \n",
    "    # Default to regular tournament selection\n",
    "    return max(participants, key=lambda ind: ind.fitness)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def enhanced_mutate(ind, gp_instance, generation):\n",
    "    \n",
    "    ind_copy = copy.deepcopy(ind)\n",
    "    \n",
    "    current_size = len(collect_nodes(ind_copy))\n",
    "    current_depth = get_tree_depth(ind_copy)\n",
    "    \n",
    "    # Growth factor increases with generation\n",
    "    growth_factor = min(0.8, generation / NUM_GENS)\n",
    "    \n",
    "    strategies = get_mutation_strategies(current_size, growth_factor)\n",
    "    \n",
    "    strategy = select_mutation_strategy(strategies)\n",
    "    \n",
    "    all_nodes = collect_nodes(ind_copy)\n",
    "    \n",
    "    # Select a node to mutate, with bias toward appropriate nodes for the strategy\n",
    "    node = select_node_for_mutation(all_nodes, strategy)\n",
    "    \n",
    "    if strategy == \"point_mutation\":\n",
    "        ind_copy = apply_point_mutation(ind_copy, node, gp_instance, current_depth, MAX_TREE_DEPTH)\n",
    "    elif strategy == \"subtree_replacement\":\n",
    "        ind_copy = apply_subtree_replacement(ind_copy, node, gp_instance, generation, current_depth, MAX_TREE_DEPTH)\n",
    "    elif strategy == \"grow\":\n",
    "        ind_copy = apply_grow_mutation(ind_copy, node, gp_instance, generation, current_depth, MAX_TREE_DEPTH)\n",
    "    elif strategy == \"shrink\":\n",
    "        ind_copy = apply_shrink_mutation(ind_copy, node)\n",
    "    \n",
    "    # Validate the tree after mutation\n",
    "    ind_copy = validate_and_fix_tree(ind_copy)\n",
    "    \n",
    "    return ind_copy\n",
    "\n",
    "\n",
    "def growth_enhanced_crossover(parent1, parent2, generation):\n",
    "    \n",
    "    # Make deep copies to avoid modifying the parents\n",
    "    child1 = copy.deepcopy(parent1)\n",
    "    child2 = copy.deepcopy(parent2)\n",
    "    \n",
    "    # Allow crossover to become more aggressive in later generations\n",
    "    growth_bias = min(0.8, 0.3 + (generation / NUM_GENS) * 0.5)\n",
    "    \n",
    "    # Select nodes from both parents, with increasing bias towards internal nodes\n",
    "    # that could lead to more interesting genetic material exchange\n",
    "    nodes1 = collect_nodes(child1)\n",
    "    nodes2 = collect_nodes(child2)\n",
    "    \n",
    "    point1 = select_crossover_point(nodes1, growth_bias)\n",
    "    point2 = select_crossover_point(nodes2, growth_bias)\n",
    "    \n",
    "    # If valid crossover points found in both trees\n",
    "    if point1 and point2:\n",
    "        # Find parent nodes for each selected crossover point\n",
    "        parent_nodes1 = [n for n in nodes1 if point1 in n.successors]\n",
    "        parent_nodes2 = [n for n in nodes2 if point2 in n.successors]\n",
    "        \n",
    "        if parent_nodes1 and parent_nodes2:\n",
    "            # Perform the crossover by swapping subtrees\n",
    "            swap_subtrees(parent_nodes1[0], parent_nodes2[0], point1, point2)\n",
    "            \n",
    "            if not is_valid_depth(child1, child2, generation):\n",
    "                # If constraints violated, create new children with appropriate sizes\n",
    "                size1 = len(collect_nodes(parent1))\n",
    "                size2 = len(collect_nodes(parent2))\n",
    "                child1 = gp.create_individual(size1)\n",
    "                child2 = gp.create_individual(size2)\n",
    "    \n",
    "    return child1, child2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diversity injection that creates larger trees in later generations\n",
    "def enhanced_diversity_injection(population, gp_instance, generation):\n",
    "    diversity = calculate_population_diversity(population)\n",
    "    \n",
    "    # Calculate average tree size\n",
    "    sizes = [len(collect_nodes(ind)) for ind in population]\n",
    "    avg_size = np.mean(sizes)\n",
    "    max_size = max(sizes)\n",
    "    \n",
    "    # More aggressive diversity injection as generations progress\n",
    "    diversity_threshold = max(0.1, 0.3 - (generation / NUM_GENS) * 0.1)\n",
    "    \n",
    "    # Inject diversity if population is too homogeneous or trees are too small\n",
    "    if diversity < diversity_threshold or (generation > NUM_GENS * 0.5 and max_size < 20):\n",
    "        print(f\"Generation {generation}: Low diversity ({diversity:.2f}) or small trees (avg:{avg_size:.1f}, max:{max_size}). Injecting new individuals.\")\n",
    "        \n",
    "        # Replace more individuals in later generations\n",
    "        replacement_rate = min(0.2, 0.1 + (generation / NUM_GENS) * 0.1)\n",
    "        num_to_replace = max(1, int(replacement_rate * len(population)))\n",
    "        \n",
    "        if generation > NUM_GENS * 0.4 and avg_size < 15:\n",
    "            # Replace smallest trees with some probability\n",
    "            candidates = [(i, ind) for i, ind in enumerate(population) \n",
    "                         if len(collect_nodes(ind)) < avg_size * 0.8]\n",
    "            if candidates:\n",
    "                # Replace some smallest trees\n",
    "                small_indices = [i for i, _ in sorted(candidates, key=lambda x: len(collect_nodes(x[1])))[:num_to_replace//2]]\n",
    "                # replace some lowest fitness individuals\n",
    "                sorted_pop = sorted(enumerate(population), key=lambda x: x[1].fitness)\n",
    "                low_fitness_indices = [i for i, _ in sorted_pop[:num_to_replace - len(small_indices)]]\n",
    "                indices_to_replace = small_indices + low_fitness_indices\n",
    "            else:\n",
    "                # Default to replacing lowest fitness\n",
    "                sorted_pop = sorted(enumerate(population), key=lambda x: x[1].fitness)\n",
    "                indices_to_replace = [i for i, _ in sorted_pop[:num_to_replace]]\n",
    "        else:\n",
    "            # Default to replacing lowest fitness\n",
    "            sorted_pop = sorted(enumerate(population), key=lambda x: x[1].fitness)\n",
    "            indices_to_replace = [i for i, _ in sorted_pop[:num_to_replace]]\n",
    "        \n",
    "        # Create new individuals with size scaling with generation\n",
    "        new_individuals = []\n",
    "        for _ in range(len(indices_to_replace)):\n",
    "            # Progressively larger trees as generations increase\n",
    "            min_size = INITIAL_SIZE_MIN + int((generation / NUM_GENS) * 3)\n",
    "            max_size = INITIAL_SIZE_MAX + int((generation / NUM_GENS) * 15)\n",
    "            \n",
    "            size = np.random.randint(min_size, max_size + 1)\n",
    "            new_ind = gp_instance.create_individual(size)\n",
    "            new_ind.fitness = unified_compute_fitness(new_ind, generation)\n",
    "            new_individuals.append(new_ind)\n",
    "        \n",
    "        # Replace selected individuals\n",
    "        for idx, new_ind in zip(indices_to_replace, new_individuals):\n",
    "            population[idx] = new_ind\n",
    "    \n",
    "    return population\n",
    "\n",
    "# -------------------------------\n",
    "# Adaptive Diversity Maintenance\n",
    "# -------------------------------\n",
    "def calculate_population_diversity(population, sample_size=None):\n",
    "    \n",
    "    if sample_size and sample_size < len(population):\n",
    "        individuals = random.sample(population, sample_size)\n",
    "    else:\n",
    "        individuals = population\n",
    "    \n",
    "    n = len(individuals)\n",
    "    if n <= 1:\n",
    "        return 0.0\n",
    "    \n",
    "    # Calculate pairwise distances\n",
    "    total_distance = 0.0\n",
    "    pair_count = 0\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            distance = semantic_distance(individuals[i], individuals[j], x_data)\n",
    "            if distance != float('inf'):\n",
    "                total_distance += distance\n",
    "                pair_count += 1\n",
    "                \n",
    "    # Normalize and return diversity score\n",
    "    if pair_count > 0:\n",
    "        avg_distance = total_distance / pair_count\n",
    "        normalized_diversity = min(1.0, avg_distance / 10.0)\n",
    "        return normalized_diversity\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "def enhanced_diversity_injection(population, gp_instance, generation):\n",
    "    \n",
    "    # Early generations: subtle diversity, later generations: more aggressive\n",
    "    diversity_rate = 0.05 + (generation / NUM_GENS) * 0.15\n",
    "    \n",
    "    current_diversity = calculate_population_diversity(population, sample_size=min(20, len(population)))\n",
    "    \n",
    "    # Only inject if diversity is low\n",
    "    if current_diversity < 0.3 or (generation % 10 == 0 and generation > 0):\n",
    "        num_to_inject = max(1, int(POP_SIZE * diversity_rate))\n",
    "        \n",
    "        # Identify individuals to replace (lower fitness ones)\n",
    "        population_sorted = sorted(population, key=lambda ind: ind.fitness)\n",
    "        to_replace = population_sorted[:num_to_inject]\n",
    "        \n",
    "        # Create new diverse individuals\n",
    "        for i in range(num_to_inject):\n",
    "            # More aggressive size scaling with generation\n",
    "            base_size = 3 + int((generation / NUM_GENS) * 12)\n",
    "            size_range = max(INITIAL_SIZE_MIN, base_size + np.random.randint(-2, 5))\n",
    "            size = np.random.randint(INITIAL_SIZE_MIN, size_range + 1)\n",
    "            \n",
    "            new_ind = gp_instance.create_individual(size)\n",
    "            new_ind.fitness = unified_compute_fitness(new_ind, generation)\n",
    "            \n",
    "            # Replace in the population\n",
    "            idx = population.index(to_replace[i])\n",
    "            population[idx] = new_ind\n",
    "            \n",
    "        print(f\"Generation {generation}: Injected {num_to_inject} new individuals for diversity\")\n",
    "    \n",
    "    return population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Add special solutions to the population\\nvalid_solutions = []\\nspecial_solutions = try_create_special_solutions()\\n\\nfor solution in special_solutions:\\n    try:\\n        # Test if the solution can be evaluated\\n        _ = gp.evaluate(solution, x_data[:1], variable_names=[f\\'x{i}\\' for i in range(x_data.shape[1])])\\n        solution.fitness = unified_compute_fitness(solution)\\n        valid_solutions.append(solution)\\n    except Exception as e:\\n        print(f\"Error evaluating solution: {e}\")\\n\\n# Now add the valid solutions to the population\\nfor solution in valid_solutions:\\n    if len(population) >= POP_SIZE:\\n        # Replace a random individual with lower fitness.\\n        lower_half = sorted(population, key=lambda ind: ind.fitness)[:POP_SIZE // 2]\\n        to_replace = np.random.choice(lower_half)\\n        population.remove(to_replace)\\n    \\n    population.append(solution)'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# Initialize population with more diversity\n",
    "# -------------------------------\n",
    "\n",
    "\n",
    "#USELESS, REMOVED FROM MAIN\n",
    "\n",
    "# Try to include specialized solutions like sin(x0)\n",
    "#used done\n",
    "def try_create_special_solutions():\n",
    "    \"\"\"Try to create potential solutions directly.\"\"\"\n",
    "    special_solutions = []\n",
    "    \n",
    "    # Make sure we're using the correct variable naming convention\n",
    "    # Check how many variables we have first\n",
    "    num_vars = x_data.shape[1]\n",
    "    \n",
    "    # Create terminal nodes by directly instantiating Node with a string,\n",
    "    # which, per the teacher library, creates a terminal.\n",
    "    if num_vars >= 1:\n",
    "        try:\n",
    "            # Create sin(x0)\n",
    "            x0_node = Node(\"x0\")\n",
    "            sin_node = Node(custom_sin, [x0_node], name=\"custom_sin\")\n",
    "            special_solutions.append(sin_node)\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating sin(x0): {e}\")\n",
    "    \n",
    "    if num_vars >= 2:\n",
    "        try:\n",
    "            # Create x0 + x1 using the library's Node constructor for operators\n",
    "            x0_node = Node(\"x0\")\n",
    "            x1_node = Node(\"x1\")\n",
    "            add_node = Node(operator.add, [x0_node, x1_node], name=\"add\")\n",
    "            special_solutions.append(add_node)\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating x0 + x1: {e}\")\n",
    "        \n",
    "        try:\n",
    "            # Create x0 * x1\n",
    "            x0_node = Node(\"x0\")\n",
    "            x1_node = Node(\"x1\")\n",
    "            mul_node = Node(operator.mul, [x0_node, x1_node], name=\"mul\")\n",
    "            special_solutions.append(mul_node)\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating x0 * x1: {e}\")\n",
    "    \n",
    "    if num_vars >= 1:\n",
    "        try:\n",
    "            # Create sin(cos(x0))\n",
    "            x0_node = Node(\"x0\")\n",
    "            cos_node = Node(custom_cos, [x0_node], name=\"custom_cos\")\n",
    "            sin_node = Node(custom_sin, [cos_node], name=\"custom_sin\")\n",
    "            special_solutions.append(sin_node)\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating sin(cos(x0)): {e}\")\n",
    "    \n",
    "    return special_solutions\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "\n",
    "#do i really need this? the main is below\n",
    "\n",
    "\n",
    "\"\"\"# Add special solutions to the population\n",
    "valid_solutions = []\n",
    "special_solutions = try_create_special_solutions()\n",
    "\n",
    "for solution in special_solutions:\n",
    "    try:\n",
    "        # Test if the solution can be evaluated\n",
    "        _ = gp.evaluate(solution, x_data[:1], variable_names=[f'x{i}' for i in range(x_data.shape[1])])\n",
    "        solution.fitness = unified_compute_fitness(solution)\n",
    "        valid_solutions.append(solution)\n",
    "    except Exception as e:\n",
    "        print(f\"Error evaluating solution: {e}\")\n",
    "\n",
    "# Now add the valid solutions to the population\n",
    "for solution in valid_solutions:\n",
    "    if len(population) >= POP_SIZE:\n",
    "        # Replace a random individual with lower fitness.\n",
    "        lower_half = sorted(population, key=lambda ind: ind.fitness)[:POP_SIZE // 2]\n",
    "        to_replace = np.random.choice(lower_half)\n",
    "        population.remove(to_replace)\n",
    "    \n",
    "    population.append(solution)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def run_streamlined_evolution():\n",
    "    \n",
    "    global LENGTH_PENALTY, population\n",
    "    \n",
    "    history = {\n",
    "        'best_fitness': [],\n",
    "        'avg_fitness': [],\n",
    "        'complexity': [],\n",
    "        'diversity': []\n",
    "    }\n",
    "    \n",
    "    state = {\n",
    "        'stagnation_counter': 0,\n",
    "        'last_best_fitness': float('-inf'),\n",
    "        'growth_stagnation': 0,\n",
    "        'max_size_seen': max(len(collect_nodes(ind)) for ind in population),\n",
    "        'found_special_solution': False,\n",
    "        'special_solution_gen': -1,\n",
    "        'best_formula_found': \"\"\n",
    "    }\n",
    "    \n",
    "    # Sort initial population by fitness (highest first)\n",
    "    population = sorted(population, key=lambda ind: ind.fitness, reverse=True)\n",
    "    \n",
    "    # Main evolutionary loop\n",
    "    for gen in tqdm(range(NUM_GENS), desc=\"Generations\", leave=True):\n",
    "        # ---- PHASE 1: Diversity and Offspring Generation ----\n",
    "        \n",
    "        # Inject diversity to prevent premature convergence\n",
    "        population = enhanced_diversity_injection(population, gp, gen)\n",
    "        \n",
    "        # Determine offspring count based on stagnation indicators\n",
    "        offspring_size = OFFSPRING_NUM\n",
    "        if state['stagnation_counter'] > 10:\n",
    "            offspring_size = int(OFFSPRING_NUM * 1.5)\n",
    "            tqdm.write(f\"Generation {gen}: Fitness stagnation detected. Increasing offspring to {offspring_size}\")\n",
    "        if state['growth_stagnation'] > 8:\n",
    "            offspring_size = int(offspring_size * 1.2)\n",
    "            tqdm.write(f\"Generation {gen}: Size stagnation detected. Further increasing offspring to {offspring_size}\")\n",
    "        \n",
    "        # ---- PHASE 2: Generate New Offspring ----\n",
    "        new_offspring = []\n",
    "        \n",
    "        # Generate offspring through crossover and mutation\n",
    "        while len(new_offspring) < offspring_size:\n",
    "            # Select first parent using tournament selection\n",
    "            parent1 = tournament_select(population, gen)                    \n",
    "            \n",
    "            if np.random.rand() < CROSSOVER_PROB:\n",
    "                # Crossover operation\n",
    "                parent2 = tournament_select(population, gen)\n",
    "                child1, child2 = growth_enhanced_crossover(parent1, parent2, gen)\n",
    "                \n",
    "                # Validate children\n",
    "                child1 = validate_and_fix_tree(child1)\n",
    "                child2 = validate_and_fix_tree(child2)\n",
    "                \n",
    "                # Apply semantic check and additional mutation if needed\n",
    "                if semantic_distance(child1, parent1, x_data) < MIN_SEMANTIC_THRESHOLD:\n",
    "                    child1 = enhanced_mutate(child1, gp, gen)\n",
    "                    child1 = validate_and_fix_tree(child1)\n",
    "                    \n",
    "                new_offspring.append(child1)\n",
    "                \n",
    "                # Add second child if space allows\n",
    "                if len(new_offspring) < offspring_size:\n",
    "                    if semantic_distance(child2, parent2, x_data) < MIN_SEMANTIC_THRESHOLD:\n",
    "                        child2 = enhanced_mutate(child2, gp, gen)\n",
    "                        child2 = validate_and_fix_tree(child2)\n",
    "                    new_offspring.append(child2)\n",
    "            else:\n",
    "                # Mutation operation\n",
    "                mutant = enhanced_mutate(parent1, gp, gen)\n",
    "                mutant = validate_and_fix_tree(mutant)\n",
    "                \n",
    "                # Check semantic difference and possibly mutate again\n",
    "                if semantic_distance(mutant, parent1, x_data) < MIN_SEMANTIC_THRESHOLD:\n",
    "                    mutant = enhanced_mutate(mutant, gp, gen)\n",
    "                    mutant = validate_and_fix_tree(mutant)\n",
    "                    \n",
    "                new_offspring.append(mutant)\n",
    "                \n",
    "            # Stop after generating enough offspring\n",
    "            if len(new_offspring) >= offspring_size:\n",
    "                break\n",
    "        \n",
    "        # ---- PHASE 3: Evaluate Offspring ----\n",
    "        for ind in new_offspring:\n",
    "            ind.fitness = unified_compute_fitness(ind, gen)\n",
    "        \n",
    "        # ---- PHASE 4: Selection with Size Diversity Preservation ----\n",
    "        population.extend(new_offspring)\n",
    "        \n",
    "        # Selection strategy\n",
    "        if gen > NUM_GENS * 0.3 and np.random.rand() < 0.3:\n",
    "            # Occasionally preserve some large trees to maintain structural diversity\n",
    "            population.sort(key=lambda ind: ind.fitness, reverse=True)\n",
    "            selected = population[:int(POP_SIZE * 0.9)]\n",
    "            remaining = population[int(POP_SIZE * 0.9):]\n",
    "            largest_trees = sorted(remaining, key=lambda ind: len(collect_nodes(ind)), reverse=True)\n",
    "            selected.extend(largest_trees[:POP_SIZE - len(selected)])\n",
    "            population = selected\n",
    "        else:\n",
    "            # Standard selection by fitness\n",
    "            population = sorted(population, key=lambda ind: ind.fitness, reverse=True)[:POP_SIZE]\n",
    "        \n",
    "        # ---- PHASE 5: Compute Statistics ----\n",
    "        best_fitness = population[0].fitness\n",
    "        avg_fitness = np.mean([ind.fitness for ind in population])\n",
    "        best_complexity = len(collect_nodes(population[0]))\n",
    "        current_max_size = max(len(collect_nodes(ind)) for ind in population)\n",
    "        diversity = calculate_population_diversity(population, sample_size=min(20, len(population)))\n",
    "        \n",
    "        # Update history\n",
    "        history['best_fitness'].append(best_fitness)\n",
    "        history['avg_fitness'].append(avg_fitness)\n",
    "        history['complexity'].append(best_complexity)\n",
    "        history['diversity'].append(diversity)\n",
    "        \n",
    "        # ---- PHASE 6: Stagnation Detection and Response ----\n",
    "        \n",
    "        # Check fitness stagnation\n",
    "        if best_fitness <= state['last_best_fitness'] + 1e-6:\n",
    "            state['stagnation_counter'] += 1\n",
    "        else:\n",
    "            state['stagnation_counter'] = 0\n",
    "            state['last_best_fitness'] = best_fitness\n",
    "        \n",
    "        # Check growth stagnation\n",
    "        if current_max_size <= state['max_size_seen']:\n",
    "            state['growth_stagnation'] += 1\n",
    "        else:\n",
    "            state['growth_stagnation'] = 0\n",
    "            state['max_size_seen'] = current_max_size\n",
    "        \n",
    "        # ---- PHASE 7: Adaptive Control Mechanisms ----\n",
    "        \n",
    "        # Control size explosion if trees are growing too fast without fitness improvement\n",
    "        if (current_max_size > 50 and state['stagnation_counter'] > 15) or current_max_size > 100:\n",
    "            old_penalty = LENGTH_PENALTY\n",
    "            LENGTH_PENALTY = old_penalty * 2\n",
    "            tqdm.write(f\"Generation {gen}: Controlling bloat. Increasing penalty temporarily from {old_penalty:.6f} to {LENGTH_PENALTY:.6f}\")\n",
    "            for ind in population:\n",
    "                ind.fitness = unified_compute_fitness(ind, gen)\n",
    "            if gen > 3:\n",
    "                LENGTH_PENALTY = old_penalty\n",
    "                \n",
    "        # Accelerate growth when trees are too small\n",
    "        if gen > 10 and state['max_size_seen'] < 15 and state['growth_stagnation'] > 5:\n",
    "            old_penalty = LENGTH_PENALTY\n",
    "            LENGTH_PENALTY = old_penalty * 0.1\n",
    "            tqdm.write(f\"Generation {gen}: Trees too small. Drastically reducing complexity penalty from {old_penalty:.6f} to {LENGTH_PENALTY:.6f}\")\n",
    "            \n",
    "            # Inject larger trees into population\n",
    "            num_large_trees = POP_SIZE // 10\n",
    "            for _ in range(num_large_trees):\n",
    "                size = np.random.randint(15, 25)\n",
    "                new_ind = gp.create_individual(size)\n",
    "                new_ind.fitness = unified_compute_fitness(new_ind, gen)\n",
    "                \n",
    "                # Replace individuals from the bottom half of the population\n",
    "                bottom_half = sorted(population, key=lambda ind: ind.fitness)[:POP_SIZE // 2]\n",
    "                to_replace = np.random.choice(bottom_half)\n",
    "                idx = population.index(to_replace)\n",
    "                population[idx] = new_ind\n",
    "                \n",
    "            state['growth_stagnation'] = 0\n",
    "        \n",
    "        # ---- PHASE 8: Special Solution Detection ----\n",
    "        #used at the beginning of the project, in the problem 1 to see if i got the right solution\n",
    "        best_formula = population[0].long_name.lower()\n",
    "        \n",
    "        \"\"\"if not state['found_special_solution']:\n",
    "            if \"sin(x0)\" in best_formula or \"custom_sin(x0)\" in best_formula:\n",
    "                state['found_special_solution'] = True\n",
    "                state['special_solution_gen'] = gen\n",
    "                state['best_formula_found'] = \"sin(x0)\"\n",
    "                tqdm.write(f\"Found sin(x0) at generation {gen}!\")\"\"\"\n",
    "        \n",
    "        # ---- PHASE 9: Logging ----\n",
    "        if gen % 5 == 0 or gen == NUM_GENS - 1:\n",
    "            current_sizes = [len(collect_nodes(ind)) for ind in population]\n",
    "            tqdm.write(f\"Generation {gen}: Best Fitness = {best_fitness:.6f}, Avg Fitness = {avg_fitness:.6f}\")\n",
    "            tqdm.write(f\"Tree sizes: Min = {min(current_sizes)}, Avg = {sum(current_sizes)/len(current_sizes):.1f}, Max = {max(current_sizes)}\")\n",
    "            tqdm.write(f\"Best complexity: {best_complexity}, Diversity: {diversity:.2f}\")\n",
    "            tqdm.write(f\"Best formula: {population[0].long_name}\")\n",
    "    \n",
    "    return (population, history['best_fitness'], history['avg_fitness'], \n",
    "            history['complexity'], history['diversity'], state['found_special_solution'], \n",
    "            state['special_solution_gen'], state['best_formula_found'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading problem 8...\n",
      "Data shape: x=(2000, 6), y=(2000,)\n",
      "Initializing GP system...\n",
      "Initializing population...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matti\\AppData\\Local\\Temp\\ipykernel_14616\\1686486328.py:53: RuntimeWarning: overflow encountered in power\n",
      "  return np.power(base, y)\n",
      "C:\\Users\\matti\\AppData\\Local\\Temp\\ipykernel_14616\\1686486328.py:81: RuntimeWarning: overflow encountered in exp\n",
      "  return np.where(x > 0, x, alpha * (np.exp(x) - 1))\n",
      "C:\\Users\\matti\\AppData\\Local\\Temp\\ipykernel_14616\\1686486328.py:65: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "C:\\Users\\matti\\AppData\\Local\\Temp\\ipykernel_14616\\1686486328.py:81: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  return np.where(x > 0, x, alpha * (np.exp(x) - 1))\n",
      "C:\\Users\\matti\\AppData\\Local\\Temp\\ipykernel_14616\\1120364458.py:15: RuntimeWarning: overflow encountered in square\n",
      "  mse_val = np.mean((pred - y_true) ** 2)\n",
      "C:\\Users\\matti\\AppData\\Local\\Temp\\ipykernel_14616\\1686486328.py:106: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  return 2 * np.abs(2 * (x / (2 * np.pi) - np.floor(x / (2 * np.pi) + 0.5))) - 1\n",
      "C:\\Users\\matti\\AppData\\Local\\Temp\\ipykernel_14616\\1686486328.py:89: RuntimeWarning: overflow encountered in exp\n",
      "  return x * np.tanh(np.log1p(np.exp(x)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial population size: 2000\n",
      "\n",
      "Starting evolutionary process...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bb4f8b211204596a03c1254451f44f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generations:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matti\\AppData\\Local\\Temp\\ipykernel_14616\\1686486328.py:115: RuntimeWarning: overflow encountered in scalar power\n",
      "  return (np.sqrt(x ** 2 + 1) - 1) / 2 + x\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 0: Best Fitness = -13392930.200407, Avg Fitness = -22392017.399879\n",
      "Tree sizes: Min = 2, Avg = 14.1, Max = 41\n",
      "Best complexity: 11, Diversity: 1.00\n",
      "Best formula: safe_pow(elu(safe_pow(-0.502751, -2.90895), 0.567784), add(gaussian(-3.72436), mish(x5)))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matti\\AppData\\Local\\Temp\\ipykernel_14616\\1686486328.py:81: RuntimeWarning: overflow encountered in scalar multiply\n",
      "  return np.where(x > 0, x, alpha * (np.exp(x) - 1))\n",
      "C:\\Users\\matti\\AppData\\Local\\Temp\\ipykernel_14616\\1686486328.py:81: RuntimeWarning: invalid value encountered in multiply\n",
      "  return np.where(x > 0, x, alpha * (np.exp(x) - 1))\n",
      "C:\\Users\\matti\\AppData\\Local\\Temp\\ipykernel_14616\\1686486328.py:133: RuntimeWarning: invalid value encountered in remainder\n",
      "  return np.mod(x, y + 1e-6)\n",
      "C:\\Users\\matti\\AppData\\Local\\Temp\\ipykernel_14616\\1686486328.py:133: RuntimeWarning: overflow encountered in remainder\n",
      "  return np.mod(x, y + 1e-6)\n",
      "C:\\Users\\matti\\AppData\\Local\\Temp\\ipykernel_14616\\1686486328.py:10: RuntimeWarning: invalid value encountered in cos\n",
      "  return np.cos(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 5: Best Fitness = -10479329.055322, Avg Fitness = -10946309.958096\n",
      "Tree sizes: Min = 5, Avg = 22.7, Max = 44\n",
      "Best complexity: 24, Diversity: 1.00\n",
      "Best formula: safe_div(mod(custom_sin(custom_tanh(elu(safe_pow(add(0.507754, x4), -2.90895), 0.567784))), mod(custom_exp(x5), sub(x5, square(mul(-2.32366, elu(4.33467, 0.567784)))))), custom_exp(x5))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\matti\\OneDrive\\Desktop\\Uni\\Quinto_anno\\Computational_intelligence\\Labs\\Squillero\\computational-intelligence\\2024-25\\project-work\\src\\gxgp\\node.py:27: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  return node(*_args)\n",
      "C:\\Users\\matti\\AppData\\Local\\Temp\\ipykernel_14616\\1686486328.py:110: RuntimeWarning: invalid value encountered in sin\n",
      "  return np.sign(np.sin(x))\n",
      "c:\\Users\\matti\\OneDrive\\Desktop\\Uni\\Quinto_anno\\Computational_intelligence\\Labs\\Squillero\\computational-intelligence\\.venv\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:3785: RuntimeWarning: invalid value encountered in sin\n",
      "  return sin(y)/y\n",
      "C:\\Users\\matti\\AppData\\Local\\Temp\\ipykernel_14616\\1686486328.py:102: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  return 2 * (x / (2 * np.pi) - np.floor(0.5 + x / (2 * np.pi)))\n",
      "C:\\Users\\matti\\AppData\\Local\\Temp\\ipykernel_14616\\1686486328.py:6: RuntimeWarning: invalid value encountered in sin\n",
      "  return np.sin(x)\n",
      "C:\\Users\\matti\\AppData\\Local\\Temp\\ipykernel_14616\\1686486328.py:57: RuntimeWarning: overflow encountered in scalar power\n",
      "  return x ** 3\n",
      "C:\\Users\\matti\\AppData\\Local\\Temp\\ipykernel_14616\\1686486328.py:69: RuntimeWarning: overflow encountered in scalar power\n",
      "  return np.exp(-x ** 2)\n",
      "C:\\Users\\matti\\AppData\\Local\\Temp\\ipykernel_14616\\1686486328.py:119: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return x / (1 + np.abs(x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 10: Injected 130 new individuals for diversity\n",
      "Generation 10: Best Fitness = -10473048.316349, Avg Fitness = -10476076.835720\n",
      "Tree sizes: Min = 22, Avg = 39.7, Max = 58\n",
      "Best complexity: 50, Diversity: 0.68\n",
      "Best formula: safe_div(mod(custom_tanh(elu(safe_pow(add(0.507754, add(0.507754, x4)), -2.90895), x5)), mod(custom_tanh(elu(safe_pow(add(0.507754, x4), -2.90895), 0.567784)), mod(custom_sin(custom_tanh(elu(safe_pow(add(0.507754, x4), -2.90895), 0.567784))), mod(custom_tanh(elu(safe_pow(add(0.507754, x4), -2.90895), 0.567784)), sub(x5, square(mul(-2.32366, elu(4.33467, 0.567784)))))))), custom_exp(x5))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matti\\AppData\\Local\\Temp\\ipykernel_14616\\1686486328.py:20: RuntimeWarning: overflow encountered in scalar divide\n",
      "  return x / (y + 1e-6)  # Add small epsilon to avoid division by zero\n",
      "C:\\Users\\matti\\AppData\\Local\\Temp\\ipykernel_14616\\1686486328.py:24: RuntimeWarning: overflow encountered in scalar power\n",
      "  return x ** 2\n",
      "C:\\Users\\matti\\AppData\\Local\\Temp\\ipykernel_14616\\1686486328.py:69: RuntimeWarning: overflow encountered in square\n",
      "  return np.exp(-x ** 2)\n",
      "C:\\Users\\matti\\AppData\\Local\\Temp\\ipykernel_14616\\1686486328.py:81: RuntimeWarning: overflow encountered in multiply\n",
      "  return np.where(x > 0, x, alpha * (np.exp(x) - 1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 14: Injected 142 new individuals for diversity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matti\\AppData\\Local\\Temp\\ipykernel_14616\\1686486328.py:77: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  return np.where(x > 0, x, alpha * x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 15: Injected 145 new individuals for diversity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matti\\AppData\\Local\\Temp\\ipykernel_14616\\1686486328.py:77: RuntimeWarning: overflow encountered in scalar multiply\n",
      "  return np.where(x > 0, x, alpha * x)\n",
      "C:\\Users\\matti\\AppData\\Local\\Temp\\ipykernel_14616\\1686486328.py:77: RuntimeWarning: invalid value encountered in multiply\n",
      "  return np.where(x > 0, x, alpha * x)\n",
      "c:\\Users\\matti\\OneDrive\\Desktop\\Uni\\Quinto_anno\\Computational_intelligence\\Labs\\Squillero\\computational-intelligence\\2024-25\\project-work\\src\\gxgp\\node.py:27: RuntimeWarning: overflow encountered in scalar multiply\n",
      "  return node(*_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 15: Best Fitness = -10470614.259777, Avg Fitness = -10472920.162238\n",
      "Tree sizes: Min = 39, Avg = 48.9, Max = 71\n",
      "Best complexity: 69, Diversity: 0.15\n",
      "Best formula: safe_div(mod(custom_tanh(elu(safe_pow(add(0.567784, add(0.507754, x4)), -2.90895), x5)), mod(custom_tanh(elu(safe_pow(add(0.507754, x4), -2.90895), 0.567784)), mod(custom_tanh(elu(safe_pow(add(0.507754, add(0.507754, x4)), -2.90895), x5)), mod(custom_tanh(elu(safe_pow(add(0.507754, x4), -2.90895), 0.567784)), mod(custom_tanh(safe_pow(add(0.507754, add(0.507754, x4)), -2.90895)), mod(custom_tanh(elu(safe_pow(add(0.507754, x4), -2.90895), 0.567784)), sub(x5, square(mul(-2.32366, elu(4.33467, 0.567784)))))))))), custom_exp(x5))\n",
      "Generation 16: Injected 148 new individuals for diversity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matti\\AppData\\Local\\Temp\\ipykernel_14616\\1686486328.py:24: RuntimeWarning: overflow encountered in square\n",
      "  return x ** 2\n",
      "C:\\Users\\matti\\AppData\\Local\\Temp\\ipykernel_14616\\1686486328.py:115: RuntimeWarning: invalid value encountered in add\n",
      "  return (np.sqrt(x ** 2 + 1) - 1) / 2 + x\n",
      "C:\\Users\\matti\\AppData\\Local\\Temp\\ipykernel_14616\\1686486328.py:115: RuntimeWarning: overflow encountered in square\n",
      "  return (np.sqrt(x ** 2 + 1) - 1) / 2 + x\n",
      "C:\\Users\\matti\\AppData\\Local\\Temp\\ipykernel_14616\\1686486328.py:57: RuntimeWarning: overflow encountered in power\n",
      "  return x ** 3\n",
      "C:\\Users\\matti\\AppData\\Local\\Temp\\ipykernel_14616\\1686486328.py:85: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  return x * sigmoid(x)\n",
      "C:\\Users\\matti\\AppData\\Local\\Temp\\ipykernel_14616\\1686486328.py:85: RuntimeWarning: invalid value encountered in multiply\n",
      "  return x * sigmoid(x)\n",
      "c:\\Users\\matti\\OneDrive\\Desktop\\Uni\\Quinto_anno\\Computational_intelligence\\Labs\\Squillero\\computational-intelligence\\2024-25\\project-work\\src\\gxgp\\node.py:27: RuntimeWarning: invalid value encountered in multiply\n",
      "  return node(*_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 20: Injected 160 new individuals for diversity\n",
      "Generation 20: Best Fitness = -10470032.807278, Avg Fitness = -10471236.191552\n",
      "Tree sizes: Min = 41, Avg = 63.0, Max = 79\n",
      "Best complexity: 76, Diversity: 0.48\n",
      "Best formula: safe_div(mod(custom_tanh(elu(safe_pow(add(0.507754, x4), -2.90895), x5)), mod(custom_tanh(elu(safe_pow(add(custom_tanh(safe_pow(add(0.507754, add(0.507754, x4)), -2.90895)), x4), -2.90895), 0.567784)), mod(custom_tanh(elu(safe_pow(add(0.507754, add(0.507754, add(0.507754, x4))), -2.90895), x5)), mod(custom_tanh(elu(safe_pow(add(0.507754, x4), -2.90895), 0.567784)), mod(custom_tanh(safe_pow(add(0.507754, add(0.507754, x4)), -2.90895)), mod(custom_tanh(elu(safe_pow(add(0.507754, x4), -2.90895), 0.567784)), sub(x5, square(mul(-2.32366, elu(4.33467, 0.567784)))))))))), custom_exp(x5))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 141\u001b[0m\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m best_individual\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 141\u001b[0m     best_solution \u001b[38;5;241m=\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[52], line 33\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Run the evolutionary algorithm\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mStarting evolutionary process...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     31\u001b[0m (final_population, best_fitness_history, avg_fitness_history, \n\u001b[0;32m     32\u001b[0m  complexity_history, diversity_history, found_special_solution, \n\u001b[1;32m---> 33\u001b[0m  special_solution_gen, best_formula_found) \u001b[38;5;241m=\u001b[39m \u001b[43mrun_streamlined_evolution\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m    \u001b[38;5;66;03m#-------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEvolution completed!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Plot fitness evolution and population statistics\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[51], line 52\u001b[0m, in \u001b[0;36mrun_streamlined_evolution\u001b[1;34m()\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrand() \u001b[38;5;241m<\u001b[39m CROSSOVER_PROB:\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;66;03m# Crossover operation\u001b[39;00m\n\u001b[0;32m     51\u001b[0m     parent2 \u001b[38;5;241m=\u001b[39m tournament_select(population, gen)\n\u001b[1;32m---> 52\u001b[0m     child1, child2 \u001b[38;5;241m=\u001b[39m \u001b[43mgrowth_enhanced_crossover\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparent1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparent2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;66;03m# Validate children\u001b[39;00m\n\u001b[0;32m     55\u001b[0m     child1 \u001b[38;5;241m=\u001b[39m validate_and_fix_tree(child1)\n",
      "Cell \u001b[1;32mIn[48], line 95\u001b[0m, in \u001b[0;36mgrowth_enhanced_crossover\u001b[1;34m(parent1, parent2, generation)\u001b[0m\n\u001b[0;32m     93\u001b[0m             size2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(collect_nodes(parent2))\n\u001b[0;32m     94\u001b[0m             child1 \u001b[38;5;241m=\u001b[39m gp\u001b[38;5;241m.\u001b[39mcreate_individual(size1)\n\u001b[1;32m---> 95\u001b[0m             child2 \u001b[38;5;241m=\u001b[39m \u001b[43mgp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_individual\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m child1, child2\n",
      "File \u001b[1;32mc:\\Users\\matti\\OneDrive\\Desktop\\Uni\\Quinto_anno\\Computational_intelligence\\Labs\\Squillero\\computational-intelligence\\2024-25\\project-work\\src\\gxgp\\gp_dag.py:34\u001b[0m, in \u001b[0;36mDagGP.create_individual\u001b[1;34m(self, n_nodes)\u001b[0m\n\u001b[0;32m     32\u001b[0m     op \u001b[38;5;241m=\u001b[39m gxgp_random\u001b[38;5;241m.\u001b[39mchoice(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_operators)\n\u001b[0;32m     33\u001b[0m     params \u001b[38;5;241m=\u001b[39m gxgp_random\u001b[38;5;241m.\u001b[39mchoices(pool, k\u001b[38;5;241m=\u001b[39marity(op))\n\u001b[1;32m---> 34\u001b[0m     individual \u001b[38;5;241m=\u001b[39m \u001b[43mNode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m     pool\u001b[38;5;241m.\u001b[39mappend(individual)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m individual\n",
      "File \u001b[1;32mc:\\Users\\matti\\OneDrive\\Desktop\\Uni\\Quinto_anno\\Computational_intelligence\\Labs\\Squillero\\computational-intelligence\\2024-25\\project-work\\src\\gxgp\\node.py:31\u001b[0m, in \u001b[0;36mNode.__init__\u001b[1;34m(self, node, successors, name)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func \u001b[38;5;241m=\u001b[39m _f\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_successors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(successors)\n\u001b[1;32m---> 31\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_arity \u001b[38;5;241m=\u001b[39m \u001b[43marity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_arity \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mtuple\u001b[39m(successors)) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_arity, (\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPanic: Incorrect number of children.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Expected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mtuple\u001b[39m(successors))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m found \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marity(node)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     35\u001b[0m )\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_leaf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\matti\\OneDrive\\Desktop\\Uni\\Quinto_anno\\Computational_intelligence\\Labs\\Squillero\\computational-intelligence\\2024-25\\project-work\\src\\gxgp\\utils.py:15\u001b[0m, in \u001b[0;36marity\u001b[1;34m(f)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21marity\u001b[39m(f: Callable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[0;32m     14\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the number of expected parameter or None if variable\"\"\"\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43minspect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetfullargspec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mvarargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     16\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\inspect.py:1388\u001b[0m, in \u001b[0;36mgetfullargspec\u001b[1;34m(func)\u001b[0m\n\u001b[0;32m   1356\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get the names and default values of a callable object's parameters.\u001b[39;00m\n\u001b[0;32m   1357\u001b[0m \n\u001b[0;32m   1358\u001b[0m \u001b[38;5;124;03mA tuple of seven things is returned:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1369\u001b[0m \u001b[38;5;124;03m  - wrapper chains defined by __wrapped__ *not* unwrapped automatically\u001b[39;00m\n\u001b[0;32m   1370\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1371\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1372\u001b[0m     \u001b[38;5;66;03m# Re: `skip_bound_arg=False`\u001b[39;00m\n\u001b[0;32m   1373\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1385\u001b[0m     \u001b[38;5;66;03m# getfullargspec() historically ignored __wrapped__ attributes,\u001b[39;00m\n\u001b[0;32m   1386\u001b[0m     \u001b[38;5;66;03m# so we ensure that remains the case in 3.3+\u001b[39;00m\n\u001b[1;32m-> 1388\u001b[0m     sig \u001b[38;5;241m=\u001b[39m \u001b[43m_signature_from_callable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1389\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mfollow_wrapper_chains\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1390\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mskip_bound_arg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1391\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43msigcls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSignature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1392\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43meval_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1393\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[0;32m   1394\u001b[0m     \u001b[38;5;66;03m# Most of the times 'signature' will raise ValueError.\u001b[39;00m\n\u001b[0;32m   1395\u001b[0m     \u001b[38;5;66;03m# But, it can also raise AttributeError, and, maybe something\u001b[39;00m\n\u001b[0;32m   1396\u001b[0m     \u001b[38;5;66;03m# else. So to be fully backwards compatible, we catch all\u001b[39;00m\n\u001b[0;32m   1397\u001b[0m     \u001b[38;5;66;03m# possible exceptions here, and reraise a TypeError.\u001b[39;00m\n\u001b[0;32m   1398\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munsupported callable\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mex\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\inspect.py:2564\u001b[0m, in \u001b[0;36m_signature_from_callable\u001b[1;34m(obj, follow_wrapper_chains, skip_bound_arg, globals, locals, eval_str, sigcls)\u001b[0m\n\u001b[0;32m   2559\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _signature_from_function(sigcls, obj,\n\u001b[0;32m   2560\u001b[0m                                     skip_bound_arg\u001b[38;5;241m=\u001b[39mskip_bound_arg,\n\u001b[0;32m   2561\u001b[0m                                     \u001b[38;5;28mglobals\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mglobals\u001b[39m, \u001b[38;5;28mlocals\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlocals\u001b[39m, eval_str\u001b[38;5;241m=\u001b[39meval_str)\n\u001b[0;32m   2563\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _signature_is_builtin(obj):\n\u001b[1;32m-> 2564\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_signature_from_builtin\u001b[49m\u001b[43m(\u001b[49m\u001b[43msigcls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2565\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mskip_bound_arg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_bound_arg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2567\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, functools\u001b[38;5;241m.\u001b[39mpartial):\n\u001b[0;32m   2568\u001b[0m     wrapped_sig \u001b[38;5;241m=\u001b[39m _get_signature_of(obj\u001b[38;5;241m.\u001b[39mfunc)\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\inspect.py:2365\u001b[0m, in \u001b[0;36m_signature_from_builtin\u001b[1;34m(cls, func, skip_bound_arg)\u001b[0m\n\u001b[0;32m   2362\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s:\n\u001b[0;32m   2363\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno signature found for builtin \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(func))\n\u001b[1;32m-> 2365\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_signature_fromstr\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_bound_arg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\inspect.py:2261\u001b[0m, in \u001b[0;36m_signature_fromstr\u001b[1;34m(cls, obj, s, skip_bound_arg)\u001b[0m\n\u001b[0;32m   2258\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m ast\u001b[38;5;241m.\u001b[39mConstant(value)\n\u001b[0;32m   2259\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m\n\u001b[1;32m-> 2261\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mclass\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43;01mRewriteSymbolics\u001b[39;49;00m\u001b[43m(\u001b[49m\u001b[43mast\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNodeTransformer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   2262\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43mvisit_Attribute\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   2263\u001b[0m \u001b[43m        \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\inspect.py:2261\u001b[0m, in \u001b[0;36m_signature_fromstr.<locals>.RewriteSymbolics\u001b[1;34m()\u001b[0m\n\u001b[0;32m   2258\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m ast\u001b[38;5;241m.\u001b[39mConstant(value)\n\u001b[0;32m   2259\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m\n\u001b[1;32m-> 2261\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mRewriteSymbolics\u001b[39;00m(ast\u001b[38;5;241m.\u001b[39mNodeTransformer):\n\u001b[0;32m   2262\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvisit_Attribute\u001b[39m(\u001b[38;5;28mself\u001b[39m, node):\n\u001b[0;32m   2263\u001b[0m         a \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \n",
    "    # Set random seed for reproducibility\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    print(f\"Loading problem {selected_problem}...\")\n",
    "    print(f\"Data shape: x={x_data.shape}, y={y_true.shape}\")\n",
    "    \n",
    "    # Initialize operators and GP system\n",
    "    print(\"Initializing GP system...\")\n",
    "    global gp, population\n",
    "    \n",
    "    \n",
    "    # Initialize population with diverse individuals\n",
    "    print(\"Initializing population...\")\n",
    "    population = []\n",
    "    \n",
    "    # Initialize with diverse sizes\n",
    "    for _ in range(POP_SIZE):\n",
    "        size = np.random.randint(INITIAL_SIZE_MIN, INITIAL_SIZE_MAX + 1)\n",
    "        ind = gp.create_individual(size)\n",
    "        ind.fitness = unified_compute_fitness(ind)\n",
    "        population.append(ind)\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(f\"Initial population size: {len(population)}\")\n",
    "    \n",
    "    # Run the evolutionary algorithm\n",
    "    print(\"\\nStarting evolutionary process...\")\n",
    "    (final_population, best_fitness_history, avg_fitness_history, \n",
    "     complexity_history, diversity_history, found_special_solution, \n",
    "     special_solution_gen, best_formula_found) = run_streamlined_evolution()    #-------------------------------------------------------------\n",
    "    \n",
    "    \n",
    "    print(\"\\nEvolution completed!\")\n",
    "    \n",
    "    # Plot fitness evolution and population statistics\n",
    "    print(\"Generating plots...\")\n",
    "    plt.figure(figsize=(15, 12))\n",
    "    \n",
    "    # Plot fitness evolution\n",
    "    plt.subplot(3, 1, 1)\n",
    "    plt.plot(best_fitness_history, label=\"Best Fitness\")\n",
    "    #plt.plot(avg_fitness_history, label=\"Average Fitness\")\n",
    "    if found_special_solution:\n",
    "        plt.axvline(x=special_solution_gen, color='r', linestyle='--', \n",
    "                    label=f\"{best_formula_found} found (gen {special_solution_gen})\")\n",
    "    plt.xlabel(\"Generation\")\n",
    "    plt.ylabel(\"Fitness (negative MSE with penalty)\")\n",
    "    plt.title(\"Evolution of Fitness\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Plot complexity\n",
    "    plt.subplot(3, 1, 2)\n",
    "    plt.plot(complexity_history, label=\"Complexity (nodes)\")\n",
    "    plt.xlabel(\"Generation\")\n",
    "    plt.ylabel(\"Number of Nodes\")\n",
    "    plt.title(\"Complexity of Best Individual\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Plot diversity\n",
    "    plt.subplot(3, 1, 3)\n",
    "    plt.plot(diversity_history, label=\"Population Diversity\", color=\"green\")\n",
    "    plt.xlabel(\"Generation\")\n",
    "    plt.ylabel(\"Diversity (semantic distance)\")\n",
    "    plt.title(\"Population Diversity\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"evolution_problem_{selected_problem}.png\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Visualize and Print the Best Individual\n",
    "    best_individual = final_population[0]\n",
    "    try:\n",
    "        best_individual.draw()  # Leverage the teacher library's built-in draw method\n",
    "        plt.title(\"Best GP Expression Tree\")\n",
    "        plt.savefig(f\"best_tree_problem_{selected_problem}.png\")\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(f\"Tree visualization failed: {e}\")\n",
    "    \n",
    "    print(\"\\nBest formula:\", best_individual.long_name)\n",
    "    \n",
    "    # Compare Model Prediction vs Ground Truth\n",
    "    predicted = gp.evaluate(best_individual, x_data, \n",
    "                            variable_names=[f'x{i}' for i in range(x_data.shape[1])])\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(predicted, label=\"GP Prediction\", color=\"blue\")\n",
    "    plt.plot(y_true, label=\"True Data\", color=\"red\", linestyle=\"--\")\n",
    "    plt.xlabel(\"Data Index\")\n",
    "    plt.ylabel(\"Output\")\n",
    "    plt.title(\"GP Model Prediction vs Ground Truth\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(f\"prediction_problem_{selected_problem}.png\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate MSE to evaluate solution quality\n",
    "    mse = np.mean((np.array(predicted) - y_true) ** 2)\n",
    "    print(f\"\\nMean Squared Error: {mse:.6f}\")\n",
    "    \n",
    "    # Split data into training and validation sets\n",
    "    split_index = int(0.8 * len(y_true))\n",
    "    x_train = x_data[:split_index]\n",
    "    x_validation = x_data[split_index:]\n",
    "    y_train = y_true[:split_index]\n",
    "    y_validation = y_true[split_index:]\n",
    "    \n",
    "    def evaluate_best(x):\n",
    "        return gp.evaluate(best_individual, x, variable_names=[f'x{i}' for i in range(x.shape[1])])\n",
    "    \n",
    "    pred_train = evaluate_best(x_train)\n",
    "    pred_validation = evaluate_best(x_validation)\n",
    "    \n",
    "    # Print MSE using teacher's style\n",
    "    train_mse = 100 * np.square(np.array(y_train) - np.array(pred_train)).sum() / len(y_train)\n",
    "    validation_mse = 100 * np.square(np.array(y_validation) - np.array(pred_validation)).sum() / len(y_validation)\n",
    "    \n",
    "    print(f\"MSE (train): {train_mse:g}\")\n",
    "    print(f\"MSE (validation): {validation_mse:g}\")\n",
    "    \n",
    "    # Save best solution information\n",
    "    with open(f\"solution_problem_{selected_problem}.txt\", \"w\") as f:\n",
    "        f.write(f\"Best formula: {best_individual.long_name}\\n\")\n",
    "        f.write(f\"MSE (train): {train_mse:g}\\n\")\n",
    "        f.write(f\"MSE (validation): {validation_mse:g}\\n\")\n",
    "        f.write(f\"Complexity (nodes): {len(collect_nodes(best_individual))}\\n\")\n",
    "        f.write(f\"Final fitness: {best_individual.fitness}\\n\")\n",
    "        if found_special_solution:\n",
    "            f.write(f\"Found {best_formula_found} at generation {special_solution_gen}\\n\")\n",
    "    \n",
    "    print(\"\\nResults saved to files.\")\n",
    "    return best_individual\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    best_solution = main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
